{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad805812",
   "metadata": {},
   "source": [
    "# Reading the SWAN-SF Dataset from File and Saving it as Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc1c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f18b0c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVTSSample:\n",
    "    \n",
    "    def __init__(self, active_region:str, flare_class:str, flare_type:str, \\\n",
    "                 verification:str, start_time:datetime, end_time:datetime, data:DataFrame):\n",
    "        self.flare_type = flare_type\n",
    "        self.active_region = active_region\n",
    "        self.flare_class = flare_class\n",
    "        self.verification = verification\n",
    "        self.start_time = start_time\n",
    "        self.end_time = end_time\n",
    "        self.data = data\n",
    "    \n",
    "    def get_flare_type(self):\n",
    "        return self.flare_type\n",
    "    \n",
    "    def get_flare_class(self):\n",
    "        return self.flare_class\n",
    "    \n",
    "    def get_active_region(self):\n",
    "        return self.active_region\n",
    "    \n",
    "    def get_verification(self):\n",
    "        return self.verification\n",
    "    \n",
    "    def get_start_time(self):\n",
    "        return self.start_time\n",
    "    \n",
    "    def get_end_time(self):\n",
    "        return self.end_time\n",
    "    \n",
    "    def get_data(self):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd78c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93c0c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mvts_instance(data_dir:str, file_name:str) -> MVTSSample:\n",
    "    # Get flare type from file name\n",
    "    if file_name[0:1] == 'F' :\n",
    "        flare_type = file_name[0:2]\n",
    "    else:\n",
    "        flare_type = file_name[0:4]\n",
    "    active_region = file_name[file_name.find('_ar')+3: file_name.find('_s2')]\n",
    "    \n",
    "    verification = 'FQ'\n",
    "    flare_class = 'FQ'\n",
    "    if file_name[0:1] != 'F' :\n",
    "        verification = file_name.split(':')[1].split('_')[0]\n",
    "        flare_class = file_name[0:1]\n",
    "    \n",
    "\n",
    "    try:\n",
    "        # Get start time from file name\n",
    "        start = file_name.find('s2')\n",
    "        start_time = file_name[start+1: start+20]\n",
    "        start_time = start_time.replace(\"T\", \" \")\n",
    "        start_time = datetime.strptime(start_time, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        # Get end time from file name\n",
    "        end = file_name.find('e2')\n",
    "        end_time = file_name[end+1: end+20]\n",
    "        end_time = end_time.replace(\"T\", \" \")\n",
    "        end_time = datetime.strptime(end_time, \"%Y-%m-%d %H:%M:%S\")\n",
    "    except ValueError:\n",
    "        print(ValueError)\n",
    "        pass\n",
    "\n",
    "    # Get data from csv file\n",
    "    try:\n",
    "        data = pd.read_csv(data_dir + \"/\" + file_name, sep=\"\\t\")\n",
    "        data['Timestamp'] = data['Timestamp'].str.replace('-', '')\n",
    "        data['Timestamp'] = data['Timestamp'].str.replace(' ', '')\n",
    "        data['Timestamp'] = data['Timestamp'].str.replace(':', '')\n",
    "    except ValueError:\n",
    "        print(ValueError)\n",
    "        pass\n",
    "    \n",
    "    # Make mvts object \n",
    "    mvts = MVTSSample(active_region, flare_class, flare_type, verification, start_time, end_time, data)\n",
    "    return mvts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2f3d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "234633c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a73d4b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_partition(partition_location:str, data_dir_save:str, abt_name:str):\n",
    "    abt_header = ['Timestamp', 'R_VALUE','TOTUSJH','TOTBSQ','TOTPOT','TOTUSJZ','ABSNJZH','SAVNCPP',\n",
    "                           'USFLUX','TOTFZ','MEANPOT', 'EPSX', 'EPSY','EPSZ','MEANSHR','SHRGT45','MEANGAM',\n",
    "                              'MEANGBT','MEANGBZ','MEANGBH','MEANJZH','TOTFY','MEANJZD','MEANALP','TOTFX']\n",
    "    \n",
    "    abt_header_label = ['FLARE_CLASS', 'FLARE_TYPE', 'ACTIVE_REGION', 'VERIFICATION']\n",
    "    \n",
    "    abt_label = pd.DataFrame(columns=abt_header_label)\n",
    "    \n",
    "\n",
    "    # Get lists of data from partition\n",
    "    FL = os.listdir(partition_location + \"/FL\")\n",
    "    NF = os.listdir(partition_location + \"/NF\")\n",
    "    FN_NO_FQ = [i for i in NF if i[0:2]!='FQ']\n",
    "    FN_FQ = [i for i in NF if i[0:2]=='FQ']\n",
    "    \n",
    "    Files = sorted(FL, reverse=True) + sorted(FN_NO_FQ, reverse=True) + FN_FQ\n",
    "    \n",
    "    number_of_features=25\n",
    "    number_of_timestamps=60\n",
    "    abt = np.zeros((number_of_timestamps,number_of_features,len(Files)))\n",
    "    \n",
    "    count = 0\n",
    "    # Add row to abt from mvssample object and its median and std data\n",
    "    with tqdm(len(Files)) as pbar:\n",
    "\n",
    "        for d in Files:\n",
    "\n",
    "            # Use temp list for each row and temp df\n",
    "            list2add_label = []\n",
    "            tempdf = pd.DataFrame(columns=abt_header)\n",
    "            tempdf_label = pd.DataFrame(columns=abt_header_label)\n",
    "\n",
    "            # Get mvs object and add flare type \n",
    "            if d in FL:\n",
    "                mvs = read_mvts_instance(partition_location + '/FL', d)\n",
    "            else:\n",
    "                mvs = read_mvts_instance(partition_location + '/NF', d)\n",
    "            list2add_label.append(mvs.get_flare_class())\n",
    "            list2add_label.append(mvs.get_flare_type())\n",
    "            list2add_label.append(mvs.get_active_region())\n",
    "            list2add_label.append(mvs.get_verification())\n",
    "\n",
    "\n",
    "            # Set up temp df for future concat with master data frame object\n",
    "            templist = mvs.get_data()[abt_header]\n",
    "            templist = templist.to_numpy()\n",
    "\n",
    "            # From data frame concat current with temp for each feature \n",
    "            abt[:,:,count] = templist\n",
    "\n",
    "            tempdf_label.loc[len(abt_header_label)] = list2add_label\n",
    "            abt_label = pd.concat([abt_label, tempdf_label], ignore_index= True, axis = 0)\n",
    "\n",
    "\n",
    "            count +=1\n",
    "            pbar.update(1)\n",
    "            \n",
    "\n",
    "    print(abt_name)        \n",
    "    print(\"shape: \" + str(abt.shape))\n",
    "    with open(data_dir_save + \"1_Raw/\" + abt_name + \".pkl\", 'wb') as f:\n",
    "        pickle.dump(abt, f)\n",
    "        \n",
    "    abt_label.to_csv(data_dir_save + \"2_Labels/\" + abt_name + \"_Labels.csv\", index=False, header=True)\n",
    "    # return the completed analitics base table\n",
    "    return abt_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e23bb61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73492it [03:33, 344.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition1\n",
      "shape: (60, 25, 73492)\n",
      "number of instances: 73492\n",
      "  FLARE_CLASS FLARE_TYPE ACTIVE_REGION VERIFICATION\n",
      "0           X       X6.9           753      Primary\n",
      "1           X       X6.9           753      Primary\n",
      "2           X       X6.9           753      Primary\n",
      "3           X       X6.9           753      Primary\n",
      "4           X       X6.9           753      Primary\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88557it [04:44, 310.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition2\n",
      "shape: (60, 25, 88557)\n",
      "number of instances: 88557\n",
      "  FLARE_CLASS FLARE_TYPE ACTIVE_REGION VERIFICATION\n",
      "0           X       X1.4          1834      Primary\n",
      "1           X       X1.4          1834      Primary\n",
      "2           X       X1.4          1834      Primary\n",
      "3           X       X1.4          1834      Primary\n",
      "4           X       X1.4          1834      Primary\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42510it [01:56, 363.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition3\n",
      "shape: (60, 25, 42510)\n",
      "number of instances: 42510\n",
      "  FLARE_CLASS FLARE_TYPE ACTIVE_REGION VERIFICATION\n",
      "0           X       X3.3          3341      Primary\n",
      "1           X       X3.3          3341      Primary\n",
      "2           X       X3.3          3341      Primary\n",
      "3           X       X3.3          3341      Primary\n",
      "4           X       X3.3          3341      Primary\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51261it [02:22, 358.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition4\n",
      "shape: (60, 25, 51261)\n",
      "number of instances: 51261\n",
      "  FLARE_CLASS FLARE_TYPE ACTIVE_REGION VERIFICATION\n",
      "0           X       X3.1          4698      Primary\n",
      "1           X       X3.1          4698      Primary\n",
      "2           X       X3.1          4698      Primary\n",
      "3           X       X3.1          4698      Primary\n",
      "4           X       X3.1          4698      Primary\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75365it [03:48, 330.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition5\n",
      "shape: (60, 25, 75365)\n",
      "number of instances: 75365\n",
      "  FLARE_CLASS FLARE_TYPE ACTIVE_REGION VERIFICATION\n",
      "0           X       X9.3          7115      Primary\n",
      "1           X       X9.3          7115      Primary\n",
      "2           X       X9.3          7115      Primary\n",
      "3           X       X9.3          7115      Primary\n",
      "4           X       X9.3          7115      Primary\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/Downloaded_Data/\"  \n",
    "data_dir_save = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/\"  \n",
    "\n",
    "# change the path to where your data is stored.\n",
    "\n",
    "num_partitions = 5\n",
    "\n",
    "for i in range(0,num_partitions):\n",
    "    abt_name = \"Partition\" + str(i+1)\n",
    "    abt = process_partition(data_dir + abt_name, data_dir_save, abt_name)\n",
    "    print(\"number of instances: \" + str(abt.shape[0]))\n",
    "    print(abt.head(5))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a9767e",
   "metadata": {},
   "source": [
    "## Missing value Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49a15156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Raw Data\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/1_Raw/\"\n",
    "raw_data = []\n",
    "\n",
    "num_partitions = 5\n",
    "\n",
    "for i in range(0,num_partitions):\n",
    "# Load the array with Pickle\n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \".pkl\", 'rb') as f:\n",
    "        raw_data.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edc6a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_missing_values(data, start_partition, end_partition):\n",
    "    abt_header = ['Timestamp', 'R_VALUE','TOTUSJH','TOTBSQ','TOTPOT','TOTUSJZ','ABSNJZH','SAVNCPP',\n",
    "                               'USFLUX','TOTFZ','MEANPOT', 'EPSX', 'EPSY','EPSZ','MEANSHR','SHRGT45','MEANGAM',\n",
    "                                  'MEANGBT','MEANGBZ','MEANGBH','MEANJZH','TOTFY','MEANJZD','MEANALP','TOTFX']\n",
    "    num_columns = 25\n",
    "    num_timestamps = 60\n",
    "    num_partitions = 5\n",
    "    null_count = [0,0,0,0,0]\n",
    "    non_null_count = [0,0,0,0,0]\n",
    "    null_count_per_feature = np.zeros((num_partitions,num_columns), dtype=int)\n",
    "\n",
    "    for i in range(start_partition-1, end_partition):\n",
    "        partition = np.array(data[i])\n",
    "\n",
    "        for j in range(0,partition.shape[2]):\n",
    "            mvts = partition[:,:, j]\n",
    "            for m in range(0,num_columns):\n",
    "                for n in range (0,num_timestamps):\n",
    "                    if (mvts[n,m] == 0.0 or mvts[n,m] == np.nan):\n",
    "                        null_count[i] += 1\n",
    "                        null_count_per_feature[i,m] += 1\n",
    "                    else:\n",
    "                        non_null_count[i] += 1\n",
    "\n",
    "        print(\"Partition\" + str(i+1) + \":\\n\")\n",
    "        print(\"null counts in P\" + str(i+1) + \": \" + str(null_count[i]))\n",
    "        print(\"non-null counts in P\"+ str(i+1) + \": \" + str(non_null_count[i]))\n",
    "        for x in range(0,num_columns):\n",
    "            print(abt_header[x] + \": \" + str(null_count_per_feature[i,x]))\n",
    "\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "960a7118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition1:\n",
      "\n",
      "null counts in P1: 2487146\n",
      "non-null counts in P1: 107750854\n",
      "Timestamp: 0\n",
      "R_VALUE: 2399220\n",
      "TOTUSJH: 652\n",
      "TOTBSQ: 652\n",
      "TOTPOT: 652\n",
      "TOTUSJZ: 652\n",
      "ABSNJZH: 652\n",
      "SAVNCPP: 652\n",
      "USFLUX: 652\n",
      "TOTFZ: 652\n",
      "MEANPOT: 0\n",
      "EPSX: 0\n",
      "EPSY: 0\n",
      "EPSZ: 0\n",
      "MEANSHR: 0\n",
      "SHRGT45: 81406\n",
      "MEANGAM: 0\n",
      "MEANGBT: 0\n",
      "MEANGBZ: 0\n",
      "MEANGBH: 0\n",
      "MEANJZH: 0\n",
      "TOTFY: 652\n",
      "MEANJZD: 0\n",
      "MEANALP: 0\n",
      "TOTFX: 652\n",
      "\n",
      "\n",
      "Partition2:\n",
      "\n",
      "null counts in P2: 4002503\n",
      "non-null counts in P2: 128832997\n",
      "Timestamp: 0\n",
      "R_VALUE: 2934918\n",
      "TOTUSJH: 93300\n",
      "TOTBSQ: 93300\n",
      "TOTPOT: 93300\n",
      "TOTUSJZ: 93300\n",
      "ABSNJZH: 93300\n",
      "SAVNCPP: 93300\n",
      "USFLUX: 93300\n",
      "TOTFZ: 93300\n",
      "MEANPOT: 0\n",
      "EPSX: 0\n",
      "EPSY: 0\n",
      "EPSZ: 0\n",
      "MEANSHR: 0\n",
      "SHRGT45: 134585\n",
      "MEANGAM: 0\n",
      "MEANGBT: 0\n",
      "MEANGBZ: 0\n",
      "MEANGBH: 0\n",
      "MEANJZH: 0\n",
      "TOTFY: 93300\n",
      "MEANJZD: 0\n",
      "MEANALP: 0\n",
      "TOTFX: 93300\n",
      "\n",
      "\n",
      "Partition3:\n",
      "\n",
      "null counts in P3: 1472395\n",
      "non-null counts in P3: 62292605\n",
      "Timestamp: 0\n",
      "R_VALUE: 1361095\n",
      "TOTUSJH: 2718\n",
      "TOTBSQ: 2718\n",
      "TOTPOT: 2718\n",
      "TOTUSJZ: 2718\n",
      "ABSNJZH: 2718\n",
      "SAVNCPP: 2725\n",
      "USFLUX: 2718\n",
      "TOTFZ: 2718\n",
      "MEANPOT: 0\n",
      "EPSX: 0\n",
      "EPSY: 0\n",
      "EPSZ: 0\n",
      "MEANSHR: 0\n",
      "SHRGT45: 84113\n",
      "MEANGAM: 0\n",
      "MEANGBT: 0\n",
      "MEANGBZ: 0\n",
      "MEANGBH: 0\n",
      "MEANJZH: 0\n",
      "TOTFY: 2718\n",
      "MEANJZD: 0\n",
      "MEANALP: 0\n",
      "TOTFX: 2718\n",
      "\n",
      "\n",
      "Partition4:\n",
      "\n",
      "null counts in P4: 1900777\n",
      "non-null counts in P4: 74990723\n",
      "Timestamp: 0\n",
      "R_VALUE: 1748394\n",
      "TOTUSJH: 4844\n",
      "TOTBSQ: 4844\n",
      "TOTPOT: 4844\n",
      "TOTUSJZ: 4844\n",
      "ABSNJZH: 4844\n",
      "SAVNCPP: 4844\n",
      "USFLUX: 4844\n",
      "TOTFZ: 4844\n",
      "MEANPOT: 0\n",
      "EPSX: 0\n",
      "EPSY: 0\n",
      "EPSZ: 0\n",
      "MEANSHR: 0\n",
      "SHRGT45: 103943\n",
      "MEANGAM: 0\n",
      "MEANGBT: 0\n",
      "MEANGBZ: 0\n",
      "MEANGBH: 0\n",
      "MEANJZH: 0\n",
      "TOTFY: 4844\n",
      "MEANJZD: 0\n",
      "MEANALP: 0\n",
      "TOTFX: 4844\n",
      "\n",
      "\n",
      "Partition5:\n",
      "\n",
      "null counts in P5: 2990768\n",
      "non-null counts in P5: 110056732\n",
      "Timestamp: 0\n",
      "R_VALUE: 2755911\n",
      "TOTUSJH: 4964\n",
      "TOTBSQ: 4964\n",
      "TOTPOT: 4964\n",
      "TOTUSJZ: 4964\n",
      "ABSNJZH: 4964\n",
      "SAVNCPP: 4964\n",
      "USFLUX: 4964\n",
      "TOTFZ: 4964\n",
      "MEANPOT: 0\n",
      "EPSX: 0\n",
      "EPSY: 0\n",
      "EPSZ: 0\n",
      "MEANSHR: 0\n",
      "SHRGT45: 185217\n",
      "MEANGAM: 0\n",
      "MEANGBT: 0\n",
      "MEANGBZ: 0\n",
      "MEANGBH: 0\n",
      "MEANJZH: 0\n",
      "TOTFY: 4964\n",
      "MEANJZD: 0\n",
      "MEANALP: 0\n",
      "TOTFX: 4964\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_missing_values(raw_data,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f2ebb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
